import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import accuracy_score
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder

# Load dataset
dt = pd.read_csv('/content/Crop_recommendation.csv')

# Encode labels
ld = LabelEncoder()
dt["label"] = ld.fit_transform(dt["label"])

# Define features and target variable
X = dt.drop(columns=['label'])
y = dt['label']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Models
models = {
    'RF': RandomForestClassifier(),
    'GB': GradientBoostingClassifier(),
    'AB': AdaBoostClassifier(),
    'XGB': XGBClassifier()
}

# Train and evaluate models
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred_train = model.predict(X_train)
    y_pred_test = model.predict(X_test)
    train_accuracy = accuracy_score(y_train, y_pred_train)
    test_accuracy = accuracy_score(y_test, y_pred_test)
    print(f"{name} - Train accuracy: {train_accuracy:.2f}, Test accuracy: {test_accuracy:.2f}")

    # Cross-validation
    scores = cross_val_score(model, X, y, cv=5)
    print(f"{name} - Cross Validation Score: {scores.mean():.2f}")

# Plotting
models = ['RF', 'GB', 'AB', 'XGB']
accuracies = [99.77, 99.09, 17.27, 99.31]

plt.bar(models, accuracies, color='maroon', width=0.5)
plt.xlabel("Models")
plt.ylabel("Accuracy")
plt.title("Accuracy of Crop Recommendation Models")
plt.show()

plt.plot(models, accuracies)
plt.xlabel("Models")
plt.ylabel("Accuracy")
plt.title("Accuracy of Crop Recommendation Models")
plt.show()
